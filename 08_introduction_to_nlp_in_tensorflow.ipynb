{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_introduction_to_nlp_in_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "I5dqhe-2w_Mp"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RI9KBgOrL3u"
      },
      "source": [
        "# Introduction to NLP in TensorFlow\n",
        "\n",
        "NLP has the goal of deriving information out of natural language (could be sequences of text or speech.)\n",
        "\n",
        "Another common term for NLP problems is sequence to sequence problems (seq2seq0)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzcJBurLrupx",
        "outputId": "b6275375-3e9a-49c8-e474-709c8d5aa2ad"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla K80 (UUID: GPU-13efc026-fe85-f51d-e6fa-c575bd30da6c)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkBHgW_mrxM_"
      },
      "source": [
        "## Get helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOBvqawBr37X",
        "outputId": "de540e73-829c-4b83-88d7-9c03b416a8a9"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-28 16:44:20--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-28 16:44:20 (53.0 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmLbpp9tr9p3"
      },
      "source": [
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T_3X1grsN0A"
      },
      "source": [
        "## Get a text dataset\n",
        "\n",
        "The dataset we are going to be using is Kaggel's introduction to NLP dataset (text samples of Tweets as disaster or not disaster).\n",
        "\n",
        "See the original source here: https://www.kaggle.com/c/nlp-getting-started"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bScfUIpnsrNd",
        "outputId": "8722106e-8e91-49cd-b0e1-a61c98b7e967"
      },
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-28 16:44:23--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.203.128, 74.125.204.128, 64.233.189.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.203.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2021-10-28 16:44:23 (90.6 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzJIwzFosy4M"
      },
      "source": [
        "# Unzip data\n",
        "unzip_data('nlp_getting_started.zip')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO1HsJjbs6qu"
      },
      "source": [
        "## Visualizing a text dataset\n",
        "\n",
        "To visualize our text sample , we first have to read them in, one way to do so would be to use Python: \n",
        "\n",
        "But I prefer to get visual staright away.\n",
        "\n",
        "So another way to do this is to use pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Kb-Qa0itRgR"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "qsMcluJct5xS",
        "outputId": "8915363d-229d-4251-b4e2-b526a0c10961"
      },
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "train_df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HjfefNU_uECf",
        "outputId": "215fb4d6-7f71-492e-8249-3319008fc9f8"
      },
      "source": [
        "train_df['text'][1]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Forest fire near La Ronge Sask. Canada'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "QF6TPQpguJ7G",
        "outputId": "5a8918ae-3d13-4fe7-a4a1-b856eeb8f5cb"
      },
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "train_df_shuffled.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "bZQciYqAuocj",
        "outputId": "2e904e7b-2390-4c90-bda9-96d13cedaeb4"
      },
      "source": [
        "# What does the test dataframe looks like\n",
        "test_df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9UXjgVquzS0",
        "outputId": "650affc1-d0d5-4c48-901f-a36fa5112d65"
      },
      "source": [
        "# How many example of each class?\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEPJWFAru-q-",
        "outputId": "b2ce9cf2-45ea-47cd-ec3c-eddb0337ceda"
      },
      "source": [
        "# How many total samples?\n",
        "len(train_df), len(test_df)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMwlyxsnverD",
        "outputId": "dc1ff73a-faf7-4571-ad3f-dae555db474f"
      },
      "source": [
        "import random\n",
        "random_index = random.randint(0, len(train_df) - 5) # create random indexes not higher than the total number samples\n",
        "for row in train_df_shuffled[['text', 'target']][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f'Target: {target}, (real disaster)' if target > 0 else '{not real disaster}')\n",
        "  print(f'Text: \\n{text}\\n')\n",
        "  print('-----\\n')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{not real disaster}\n",
            "Text: \n",
            "What. The. Fuck. https://t.co/Nv7rK63Pgc\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 1, (real disaster)\n",
            "Text: \n",
            "#LoMasVisto THOUSANDS OF HIPSTERS FEARED LOST: Giant Sinkhole Devours Brooklyn Intersectio... http://t.co/qwtk1b2fMC #CadenaDeSeguidores\n",
            "\n",
            "-----\n",
            "\n",
            "Target: 1, (real disaster)\n",
            "Text: \n",
            "@AlvinNelson07 A train isn't made to withstand collisions! Immediate derailment. It's totally fucked.\n",
            "\n",
            "-----\n",
            "\n",
            "{not real disaster}\n",
            "Text: \n",
            "Love skiing\n",
            "\n",
            "-----\n",
            "\n",
            "{not real disaster}\n",
            "Text: \n",
            "We just happened to get on the same road right behind the buses I'm dead serious\n",
            "\n",
            "-----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5dqhe-2w_Mp"
      },
      "source": [
        "### Split data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLr0TA7lyCG_"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUsjZWauyG-I"
      },
      "source": [
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled['text'].to_numpy(),\n",
        "                                                                            train_df_shuffled['target'].to_numpy(),\n",
        "                                                                            test_size=0.1,\n",
        "                                                                            random_state=42)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgcfsaO2ywhP",
        "outputId": "f9e2437e-7a3c-466b-e097-88104f68c2d3"
      },
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGV26-d4y5_R",
        "outputId": "34f6d96d-a6e2-4da2-d502-7fcee94b53a4"
      },
      "source": [
        "# Check the first 10 samples\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSYfaUYfzFqw"
      },
      "source": [
        "## Converting text into numbers\n",
        "\n",
        "When dealing with a text problem, one of the first thing you have to do before you build a model is , to convert your text to numbers.\n",
        "\n",
        "There are a few ways to do this, namely:\n",
        "* Tokenaziation - \n",
        "* Embedding - "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJJIIDgqzaFp"
      },
      "source": [
        "### Text Vectorization (tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcV-4KoW124d",
        "outputId": "57fa1f39-fce6-4ae3-ec66-0172c5b3cd0f"
      },
      "source": [
        "train_sentences[:5]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCdZwF9615WI"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok-XPKzy2rVu"
      },
      "source": [
        "# Use the default TextVectorization parameters\n",
        "text_vectorizer = TextVectorization(max_tokens=None, # How many words in the vocabluary (automatically add <00V>)\n",
        "                                    standardize='lower_and_strip_punctuation',\n",
        "                                    split='whitespace',\n",
        "                                    ngrams=None, # create groups of n-words?,\n",
        "                                    output_mode='int', # how to map tokens to numbers\n",
        "                                    output_sequence_length=None, # how long do you want your sequences to be.,\n",
        "                                    pad_to_max_tokens=False,\n",
        "                                    ) "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYPo3XVS5Gss",
        "outputId": "3f8dc9b2-e79e-48fd-aed4-cae6f9a0699c"
      },
      "source": [
        "train_sentences[0].split()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@mogacola', '@zamtriossu', 'i', 'screamed', 'after', 'hitting', 'tweet']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DjaBa004UdI",
        "outputId": "96eba181-9fdb-4a7e-d58a-7ac794b25bdb"
      },
      "source": [
        "# Find the average number of tokens (words) in the training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5R7KlfJ5Ka_"
      },
      "source": [
        "# Setup text vectorization variables\n",
        "max_vocab_length = 10000\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from tweets does a model see)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode='int',\n",
        "                                    output_sequence_length=max_length)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQfbmKT16DP7"
      },
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBBkUkPt7BnW",
        "outputId": "924f2597-1642-4383-9ee4-853c2b82dcea"
      },
      "source": [
        "train_sentences[:10]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "       'Imagine getting flattened by Kurt Zouma',\n",
              "       '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "       \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "       'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "       '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "       'destroy the free fandom honestly',\n",
              "       'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "       '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "       'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hVxSRNf7D7Q",
        "outputId": "21f6675b-b1cf-4363-89ab-a2aeabc53f06"
      },
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "sample_sentence = 'There is a flood in my street!'\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[ 74,   9,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUCHkwRO7VbV",
        "outputId": "b4e967b1-3ef9-4fd8-b763-2dce377d02e0"
      },
      "source": [
        "# Choose random sentence from the training dataset and tokenize it\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f'original text:\\n{random_sentence}\\n\\nVectorized version:')\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original text:\n",
            "Cascada - Evacuate The Dancefloor (Official Video) https://t.co/OHCx3y8l4s via @YouTube\n",
            "\n",
            "Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[  1, 279,   2,   1, 839,  72,   1,  49, 114,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHqsQmKI73FP",
        "outputId": "42ae46a4-5d47-4608-da3f-bb5b0febbeb7"
      },
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary() # get all of the unique words in our training data\n",
        "top_5_words = words_in_vocab[:5] # get the most common words\n",
        "bottom_5_words = words_in_vocab[-5:] # get the least common words\n",
        "print(f'Number of words in vocab: {len(words_in_vocab)}')\n",
        "print(f'5 most common words: {top_5_words}')\n",
        "print(f'5 least common words: {bottom_5_words}')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glNh5sIV80tB"
      },
      "source": [
        "### Creating an Embeddingusing an Embedding Layer\n",
        "\n",
        "To make our embedding we are going to use Tensorflow's Embedding layers.\n",
        "\n",
        "The parameters we care most about for our embedding layser:\n",
        "* `input_dim` - the size of our vocabluary\n",
        "* `output_dim` - the size of output embedding vector, for example, a value of 100 would mean each token gets represented by a vector 100 long\n",
        "* `input_lenght` - length of sequences being passes to the embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSqlNDKR9hqs"
      },
      "source": [
        "from tensorflow.keras import layers"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X09rJQeY-XuY"
      },
      "source": [
        "embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                             output_dim=128,\n",
        "                             embeddings_initializer='uniform',\n",
        "                             input_length=max_length)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItRmBr---mnY",
        "outputId": "8eefac60-baa9-4075-9ddb-c42631b02b15"
      },
      "source": [
        "embedding"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7fec10629610>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zg3DvuYK-p9-",
        "outputId": "9de8619b-ad65-41c8-9e0e-e64baa3d7313"
      },
      "source": [
        "# Get a random sentence from the training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f'Original text:\\n{random_sentence}\\n\\nEmbedded version:')\n",
        "\n",
        "# Embed the random sentence (turn it into dense vectors of fixed size)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "Devastation: coming to a @Target and find the @Starbucks closed ?? #momneedscoffee #asap #iwontmakeit\n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.03313871,  0.01897602,  0.0351136 , ...,  0.0496209 ,\n",
              "         -0.00155717, -0.03285117],\n",
              "        [ 0.01636987, -0.04256427, -0.03251853, ...,  0.01121984,\n",
              "         -0.0487914 , -0.01903006],\n",
              "        [ 0.00465488, -0.01260176,  0.03700188, ..., -0.01859603,\n",
              "         -0.02317901,  0.04632098],\n",
              "        ...,\n",
              "        [-0.04571028,  0.01214402, -0.02663195, ...,  0.01795422,\n",
              "          0.04534959, -0.00791057],\n",
              "        [ 0.04494543,  0.00612792,  0.04754272, ..., -0.04387289,\n",
              "         -0.03155122,  0.01717368],\n",
              "        [ 0.04494543,  0.00612792,  0.04754272, ..., -0.04387289,\n",
              "         -0.03155122,  0.01717368]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulT3sPHd_G7d",
        "outputId": "0b1ce7c0-157b-4c76-c287-4e05546a3eec"
      },
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence[0]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([-0.03313871,  0.01897602,  0.0351136 ,  0.0104239 , -0.01501421,\n",
              "        -0.03216878,  0.00827909, -0.02668587,  0.00087991,  0.01105351,\n",
              "         0.00859736,  0.02399964, -0.04864323, -0.04765281,  0.02899996,\n",
              "        -0.02918972,  0.03106386,  0.00683875,  0.03180863,  0.0348482 ,\n",
              "        -0.02428819,  0.01328609,  0.01929427, -0.00324321, -0.01575433,\n",
              "         0.0321769 ,  0.02106461,  0.04549298,  0.00185337, -0.01134077,\n",
              "        -0.01564895, -0.02948715,  0.0095762 ,  0.02480462, -0.03499284,\n",
              "         0.03414121,  0.03984198,  0.04392072,  0.02302325,  0.03151136,\n",
              "        -0.00135468, -0.03546492, -0.0093764 , -0.03807511, -0.04791329,\n",
              "        -0.04976351,  0.03297773,  0.04085939,  0.04293844, -0.03244939,\n",
              "        -0.01574811, -0.01920158,  0.00126714, -0.03140891,  0.00770028,\n",
              "         0.03673425, -0.02306554,  0.00583789,  0.01398523, -0.01026446,\n",
              "         0.03690277, -0.04908544,  0.04391931,  0.00715343, -0.04434158,\n",
              "        -0.04844022,  0.03936818, -0.00018549,  0.02241038, -0.01481145,\n",
              "         0.02490189, -0.0171717 , -0.01607988, -0.03455969, -0.01461815,\n",
              "         0.03631679, -0.02949928, -0.03350685, -0.01219217, -0.01786805,\n",
              "         0.04769624, -0.00100964, -0.0012833 , -0.00158365,  0.00146916,\n",
              "         0.02973555,  0.02801045, -0.01074175,  0.01029109, -0.03830892,\n",
              "         0.0174516 , -0.04415184,  0.02397365,  0.03043956, -0.01663665,\n",
              "         0.03248476, -0.02857603, -0.02477199, -0.0390735 ,  0.0267644 ,\n",
              "         0.03976463,  0.04951185,  0.01588624, -0.04315868,  0.04361964,\n",
              "        -0.03527329,  0.01275088, -0.02474616, -0.021778  ,  0.04433342,\n",
              "         0.02316717,  0.02790009, -0.00221323, -0.04806998,  0.00984429,\n",
              "        -0.01034119, -0.01067113, -0.02426469,  0.04461422, -0.04878319,\n",
              "         0.0253045 ,  0.00575594, -0.03168138, -0.00545273, -0.00640504,\n",
              "         0.0496209 , -0.00155717, -0.03285117], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " 'D')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUMbBAsB_nY1"
      },
      "source": [
        "## Modeling a text dataset (running a series of experiments)\n",
        "\n",
        "No we have got a way to turn our text sequences into number, it's time to start building a series of modelling experiments.\n",
        "\n",
        "We will start with a baseline and move on from \n",
        "\n",
        "* Model 0: Naiave Bayes (baseline), this is from Sklearn ML\n",
        "map:\n",
        "\n",
        "* Model 1: \n",
        "\n",
        "* Model 2: LSTM (RNN)\n",
        "\n",
        "* Model 3: GRU model (RNN)\n",
        "\n",
        "* Model 4: Bidirectional - LSTM model(RNN)\n",
        "\n",
        "* Model 5: 1D Convolutional Neural Network (CNN)\n",
        "\n",
        "* Model 6: TensorFlow HUb Pretrained Feature Extractor (using tranfer learning for NLP)\n",
        "\n",
        "* Model 7: Same as model 6 with 10% of training data\n",
        "\n",
        "\n",
        "How are we going to approach all of these?\n",
        "\n",
        "Use the standard steps in modelling with tensorflow:\n",
        "\n",
        "* Create a Model\n",
        "*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8gTibDwZaQV"
      },
      "source": [
        "### Model 9: Getting a baseline\n",
        "\n",
        "To create our baseline we will use Sklearn's Multinomial Naive Bayes using the TD-IDF farmula to convert our words into numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQaeH25FcDjP"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KSRLpOdcXNi",
        "outputId": "012797f5-9da2-4c5d-8b75-911c2b3cb430"
      },
      "source": [
        "# Create tokenization and modeling pipeline\n",
        "model_0 = Pipeline([\n",
        "  ('tfidf', TfidfVectorizer()), # convert words to numbers\n",
        "  ('clf', MultinomialNB()) # model the text            \n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Di2OlssdHEL",
        "outputId": "951e59bd-ae88-4140-eb9d-31867f93401d"
      },
      "source": [
        "# Evalutate the model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f'Our baseline mocel achieves an accurac of: {baseline_score*100:.2f}%')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline mocel achieves an accurac of: 79.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eXWSFY6dicr",
        "outputId": "dde0a1fb-7876-4472-9c98-09815bf891ae"
      },
      "source": [
        "train_df.target.value_counts()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoPQi3QQdn6L",
        "outputId": "aaa0f9b9-3154-47db-95c9-ed0d54afd776"
      },
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dP0MYW6dwcQ"
      },
      "source": [
        "### Creating an evalutaion function for our model experiments\n",
        "\n",
        "We could evaluate all of our model's predictions with different metrics every time, however , this will be combersome and easily be fixed with a function.\n",
        "\n",
        "Let's create one to compare our model's predictions with the truth lables using the following\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5fbZQcbfSno"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQXZmD4Qfbnw"
      },
      "source": [
        "def calculate_results(y_true, y_pred):\n",
        "\n",
        "  # Calcuate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "\n",
        "  # Calculate model precision, recall and f1-score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
        "  model_results = {'accuracy': model_accuracy,\n",
        "                   'precision': model_precision,\n",
        "                   'recall': model_recall,\n",
        "                   'f1': model_f1}\n",
        "\n",
        "  return model_results               \n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDHBsCkygxq5",
        "outputId": "b274c684-8e5e-4e75-8266-4d3d5cea6040"
      },
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "\n",
        "baseline_results"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TngdeV5jhDUs"
      },
      "source": [
        "from helper_functions import calculate_results"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTxP02nMhiXf",
        "outputId": "19b2622c-7a9f-43cc-8fbd-2c203a0281bc"
      },
      "source": [
        "print(calculate_results(y_true=val_labels,\n",
        "                        y_pred=baseline_preds))"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accuracy': 79.26509186351706, 'precision': 0.8111390004213173, 'recall': 0.7926509186351706, 'f1': 0.7862189758049549}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wD2y2bJhq3G"
      },
      "source": [
        "### Model 1: A simple dense model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VqU5CRthy6c"
      },
      "source": [
        "# Create a tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save TensorBoard logs\n",
        "SAVE_DIR = 'model_logs'"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSdvu3HLiInm"
      },
      "source": [
        "# Build model with the Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string) # inputs are 1-d string\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers\n",
        "x = embedding(x) # create an embedding of the numberized inputs\n",
        "x = layers.GlobalAveragePooling1D()(x) # condense the feature vector for each token to one vector\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x) # Create the output layer, want binary outputs so use sigmoid activation function\n",
        "model_1 = tf.keras.Model(inputs, outputs, name='model_1_dense')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_gFdqk6jGjf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da2b5292-a3bb-42e2-c3eb-200ff812fcb5"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpv90uP7jIVw"
      },
      "source": [
        "# Compile the model\n",
        "model_1.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-Aihx63xJKp",
        "outputId": "f16e1f9b-a93a-420d-89f9-5a492239dec2"
      },
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name='model_1_dense')])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20211028-164431\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 9ms/step - loss: 0.6103 - accuracy: 0.6955 - val_loss: 0.5335 - val_accuracy: 0.7664\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.4401 - accuracy: 0.8202 - val_loss: 0.4702 - val_accuracy: 0.7887\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.3460 - accuracy: 0.8619 - val_loss: 0.4560 - val_accuracy: 0.7940\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.2837 - accuracy: 0.8907 - val_loss: 0.4629 - val_accuracy: 0.7927\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.2367 - accuracy: 0.9127 - val_loss: 0.4755 - val_accuracy: 0.7874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dplXyU6Rxf-r",
        "outputId": "5b96b64b-0d78-436b-df71-aa971e9a74f0"
      },
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7874\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.47551077604293823, 0.787401556968689]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKyTWY4Ixr4F",
        "outputId": "d698873a-380b-4aa1-ce78-e809fd14a052"
      },
      "source": [
        "# Make some prediction and evaluate those\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z189BR6bx3Hp",
        "outputId": "d597a308-3372-4081-d5f1-c87fa91325c5"
      },
      "source": [
        "model_1_pred_probs[0]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.4441704], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAJJmKhUx5bO",
        "outputId": "1ce7a4c8-8e5e-44b4-deba-385a8265b4d2"
      },
      "source": [
        "model_1_pred_probs[:10]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4441704 ],\n",
              "       [0.7499537 ],\n",
              "       [0.9977877 ],\n",
              "       [0.12964597],\n",
              "       [0.09317681],\n",
              "       [0.9477025 ],\n",
              "       [0.90220547],\n",
              "       [0.9939645 ],\n",
              "       [0.9713866 ],\n",
              "       [0.30075282]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtBNLWrBx_Bw",
        "outputId": "6c7eb2e2-089e-4def-9576-6d364f7560b7"
      },
      "source": [
        "val_labels"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
              "       1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
              "       1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
              "       0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
              "       0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
              "       0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
              "       1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1,\n",
              "       1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
              "       0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
              "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
              "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyTtCaHrzdGW",
        "outputId": "71274020-35a0-4deb-f185-9617410e33c1"
      },
      "source": [
        "# Convert model prediction probabilities to label format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "model_1_preds[:20]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I48KW417ztku",
        "outputId": "b056f03b-697a-4229-c081-26eae6b6fc2c"
      },
      "source": [
        "# Calcualte our model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.74015748031496,\n",
              " 'f1': 0.7849686345949081,\n",
              " 'precision': 0.790739069704199,\n",
              " 'recall': 0.7874015748031497}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMJs8vzkz5F6",
        "outputId": "5c6a9e3c-d590-4943-fcd1-a43c9e91d2a7"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOmrEU7tz7ty",
        "outputId": "fba94d37-dd79-4a89-edb2-ea011845df2b"
      },
      "source": [
        "import numpy as np\n",
        "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drvmueEt0GR9"
      },
      "source": [
        "## Visualizing learned embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGt7HZxY0jyQ",
        "outputId": "930873e7-6383-49ce-b75f-e9483a999977"
      },
      "source": [
        "\n",
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkxTJ70505Np",
        "outputId": "cf5683c9-c84c-44cc-8726-862092a92cdd"
      },
      "source": [
        "# Model 1 summary\n",
        "model_1.summary()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iz-CGtr1IrT",
        "outputId": "db7257c8-7735-41f4-9e72-39ce9e945b7a"
      },
      "source": [
        "# Get the weight matrix in embedding layer\n",
        "# (these are the numerical representations of each token in our training data, which have been learned for 5 epocsh)\n",
        "embed_weights = model_1.get_layer('embedding').get_weights()[0]\n",
        "embed_weights"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.02955481, -0.01101416,  0.0335395 , ..., -0.02798888,\n",
              "        -0.04748305,  0.00100691],\n",
              "       [-0.04978676,  0.00731625, -0.03001148, ...,  0.0225991 ,\n",
              "         0.04197403, -0.01239208],\n",
              "       [ 0.02904216,  0.01030873, -0.01485948, ...,  0.00112378,\n",
              "        -0.02365196, -0.02653028],\n",
              "       ...,\n",
              "       [ 0.04271208, -0.02424642,  0.01905931, ...,  0.01917282,\n",
              "        -0.02351713,  0.04168281],\n",
              "       [-0.05796742, -0.03225105, -0.05580724, ...,  0.02890195,\n",
              "         0.00658832, -0.07311984],\n",
              "       [-0.08446391, -0.0861695 , -0.03354079, ...,  0.107513  ,\n",
              "        -0.05915274, -0.05204869]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-4DkpEr1git",
        "outputId": "20b57100-0929-4d65-d088-779c541490d1"
      },
      "source": [
        "print(embed_weights.shape) # same size as vocab and embedding dim (output_dim of our embedding layer)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdfTeVQz175o",
        "outputId": "ba0119b1-0c86-46be-8798-dbf46bf9c69e"
      },
      "source": [
        "embed_weights"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.02955481, -0.01101416,  0.0335395 , ..., -0.02798888,\n",
              "        -0.04748305,  0.00100691],\n",
              "       [-0.04978676,  0.00731625, -0.03001148, ...,  0.0225991 ,\n",
              "         0.04197403, -0.01239208],\n",
              "       [ 0.02904216,  0.01030873, -0.01485948, ...,  0.00112378,\n",
              "        -0.02365196, -0.02653028],\n",
              "       ...,\n",
              "       [ 0.04271208, -0.02424642,  0.01905931, ...,  0.01917282,\n",
              "        -0.02351713,  0.04168281],\n",
              "       [-0.05796742, -0.03225105, -0.05580724, ...,  0.02890195,\n",
              "         0.00658832, -0.07311984],\n",
              "       [-0.08446391, -0.0861695 , -0.03354079, ...,  0.107513  ,\n",
              "        -0.05915274, -0.05204869]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBLM-P8s2FvH"
      },
      "source": [
        "Now we have got the embedding matrix our model has learned to represent our tokens, let's see how we can visualize it.\n",
        "\n",
        "To do so, TensorFlow has a "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1yYszS251Tg"
      },
      "source": [
        "import io"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBTj8amd2y9r"
      },
      "source": [
        "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "for index, word in enumerate(words_in_vocab):\n",
        "  if index == 0:\n",
        "    continue  # skip 0, it's padding.\n",
        "  vec = embed_weights[index]\n",
        "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "  out_m.write(word + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "id": "PTnZe1hs5ySf",
        "outputId": "49c039ec-2164-45d1-a863-a0e8017cf71c"
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('vectors.tsv')\n",
        "  files.download('metadata.tsv')\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_ca9fcf93-81bc-4215-a8d2-dfad6d1427ce\", \"vectors.tsv\", 15371961)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_18aaf0f5-00d9-4cf5-b753-cf9ade4b7ffe\", \"metadata.tsv\", 80388)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEz1cTB856Dt"
      },
      "source": [
        "## Recurrent Neural Networks (RNN's)\n",
        "\n",
        "RNN's are useful for sequence data.\n",
        "\n",
        "The premis of a recurrent neural network is to use the representation of a previous input to aid the representation of a later input.\n",
        "\n",
        "> **Resources**: If you want an overview of the internals of a recurrent neural network, see the following:\n",
        "- MIT's lectures : https://www.youtube.com/watch?v=5tvmMX8r_OM&list=PLtBw6njQRU-rwp5__7C0oIVt26ZgjG9NI\n",
        "\n",
        "- Chris Ola's intro ot LSTMs: \n",
        "\n",
        "- Andrej Karpathy's the unreasonable effectivenss of recurrent neural networks:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skPO83oSTgML"
      },
      "source": [
        "### Model 2: LSTM\n",
        "\n",
        "LSTM - Long Short Term Memory (one of the most popular LSTM cells)\n",
        "\n",
        "Our structure of an RNN typically looks like this:\n",
        "\n",
        "```\n",
        "Input (text) -> Tokenize -> Embedding -> Layers (RNNs/dense) -> Ouput (label probability)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVaf6LZRUut-"
      },
      "source": [
        "# Create an LSTM model\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# print(x.shape)\n",
        "# x = layers.LSTM(units=64, return_sequences=True)(x) # When you are stacking RNN cells, you need to return_sequences=True\n",
        "# print(x.shape)\n",
        "x = layers.LSTM(64)(x)\n",
        "# print(x.shape)\n",
        "# x = layers.Dense(64, activation='relu')(x)\n",
        "# print(x.shape)\n",
        "outputs =layers.Dense(1, activation='sigmoid')(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name='model_2_LSTM')"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHzfR3dDV8zv",
        "outputId": "ba9d7721-d085-4ee6-c10d-98d1004cc432"
      },
      "source": [
        "# Get a summary\n",
        "model_2.summary()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                49408     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,329,473\n",
            "Trainable params: 1,329,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKKw_0mqYmYQ"
      },
      "source": [
        "# Compile the model\n",
        "model_2.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DU4CeCYYyoo",
        "outputId": "832d8458-0588-4f95-adab-e6469c3f6b41"
      },
      "source": [
        "# Fit the model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'model_2_LSTM')])"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20211028-164444\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 7s 14ms/step - loss: 0.2192 - accuracy: 0.9221 - val_loss: 0.6133 - val_accuracy: 0.7808\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.1548 - accuracy: 0.9403 - val_loss: 0.6484 - val_accuracy: 0.7822\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1272 - accuracy: 0.9502 - val_loss: 0.6753 - val_accuracy: 0.7756\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1080 - accuracy: 0.9600 - val_loss: 0.6752 - val_accuracy: 0.7782\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.0875 - accuracy: 0.9669 - val_loss: 1.0776 - val_accuracy: 0.7717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EvaN7_6ZGYh",
        "outputId": "a1c8d952-9efa-484c-d3f2-f3df41c32824"
      },
      "source": [
        "# Make predictions with LSTM Model\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.5731885e-03],\n",
              "       [6.1019373e-01],\n",
              "       [9.9977893e-01],\n",
              "       [5.7374584e-03],\n",
              "       [3.3642238e-04],\n",
              "       [9.9923611e-01],\n",
              "       [8.0802202e-01],\n",
              "       [9.9986267e-01],\n",
              "       [9.9975950e-01],\n",
              "       [6.7366093e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaQd1lePZfXv",
        "outputId": "a80085a9-4e7e-4640-ce1a-45c52a2fb054"
      },
      "source": [
        "# Convert model 2 pred probs to labels\n",
        "model_2_pred = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_pred[:10]"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgjnishxZxSs",
        "outputId": "cbb1dc71-3e2b-407b-9a30-85306089386f"
      },
      "source": [
        "# Calculate model 2 results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_pred)\n",
        "\n",
        "model_2_results"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.16535433070865,\n",
              " 'f1': 0.7694523344399302,\n",
              " 'precision': 0.773559668677779,\n",
              " 'recall': 0.7716535433070866}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9FS5mmWZ-NE",
        "outputId": "fb8c3c04-def4-4972-be34-32cfa8ad03c8"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vJ2ZAInaEog"
      },
      "source": [
        "### Model 3: GRU\n",
        "\n",
        "Another popular and effective RNN component is the GRU or gated recurrent unit:\n",
        "\n",
        "The GRU cells has similar features to an LSTM cell but has less parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12b5trsVdbX4"
      },
      "source": [
        "# Build an RNN using the GRU cells\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# print(x.shape)\n",
        "x = layers.GRU(64, return_sequences=True)(x)\n",
        "# print(x.shape)\n",
        "# x = layers.LSTM(42, return_sequences=True)(x)\n",
        "# print(x.shape)\n",
        "# x = layers.GRU(99)(x)\n",
        "# print(x.shape)\n",
        "# x = layers.Dense(64, activation='relu')(x)\n",
        "# x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.GRU(64)(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name='model_3_GRU')"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ5pRfpQy4fe",
        "outputId": "eb850ecc-368a-4efd-c57d-f3034792b035"
      },
      "source": [
        "# Get a summary\n",
        "model_3.summary()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_11 (InputLayer)        [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "gru_13 (GRU)                 (None, 15, 64)            37248     \n",
            "_________________________________________________________________\n",
            "gru_14 (GRU)                 (None, 64)                24960     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,342,273\n",
            "Trainable params: 1,342,273\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxudGBVd0G10"
      },
      "source": [
        "# Compile the model\n",
        "model_3.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9A0VsfH1QUH",
        "outputId": "b112f5dd-403d-4b6d-840e-df3f86fe08d5"
      },
      "source": [
        "# Fit the model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name='model_3_GRU')])"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20211028-165831\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 21ms/step - loss: 0.1496 - accuracy: 0.9425 - val_loss: 0.7498 - val_accuracy: 0.7769\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0842 - accuracy: 0.9696 - val_loss: 1.0597 - val_accuracy: 0.7769\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0721 - accuracy: 0.9734 - val_loss: 0.8503 - val_accuracy: 0.7743\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0628 - accuracy: 0.9747 - val_loss: 0.9883 - val_accuracy: 0.7690\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0556 - accuracy: 0.9771 - val_loss: 0.8784 - val_accuracy: 0.7651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7G5PgtF1rku",
        "outputId": "da625866-61a4-48d7-d5d5-f5355db36502"
      },
      "source": [
        "# Make some predictions with our GRU model\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:10]"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.2086498e-01],\n",
              "       [8.7103182e-01],\n",
              "       [9.9603623e-01],\n",
              "       [8.9281917e-02],\n",
              "       [5.5703073e-04],\n",
              "       [9.9515069e-01],\n",
              "       [1.3767326e-01],\n",
              "       [9.9929559e-01],\n",
              "       [9.9864882e-01],\n",
              "       [4.0735644e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxZYeR2p175g",
        "outputId": "4500662f-6c6d-4335-b95f-8bd33268dd23"
      },
      "source": [
        "# Convert model 3 pred probs to labels\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 0., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlZaZCRW2QKJ",
        "outputId": "4b110b38-dff5-4707-e458-af8485271bbd"
      },
      "source": [
        "# Calcualte model 3 results\n",
        "model_3_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.50918635170603,\n",
              " 'f1': 0.7632813381351602,\n",
              " 'precision': 0.766006698423534,\n",
              " 'recall': 0.7650918635170604}"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxB40O1Z2spF"
      },
      "source": [
        "### Model 4: Bidirectional RNN\n",
        "\n",
        "Normal RNN's go from left to right (just like you'd read an English sentence) however bidirectional RNN's goes from right to left and also left to right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUGCLom14rM7"
      },
      "source": [
        "# Build a bidirectional RNN in TensorFlow\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype='string')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name='model_4_bidirectional')"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnaeIMOv4zoj",
        "outputId": "d308b536-9c13-4dc8-bcfc-7c49840200b1"
      },
      "source": [
        "# Get a summary\n",
        "model_4.summary()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_16 (InputLayer)        [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_1 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,378,945\n",
            "Trainable params: 1,378,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GehaMrp25ysC"
      },
      "source": [
        "# Compile model\n",
        "model_4.compile(loss='binary_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFLYdT5C6hMd",
        "outputId": "3aff343a-cb2d-48eb-9fca-d223f3f2b0ff"
      },
      "source": [
        "# Fit the model\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     'model_4_bidirectional')])"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20211028-172100\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 21ms/step - loss: 0.1098 - accuracy: 0.9650 - val_loss: 0.9295 - val_accuracy: 0.7651\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0549 - accuracy: 0.9756 - val_loss: 1.1174 - val_accuracy: 0.7730\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0482 - accuracy: 0.9793 - val_loss: 1.2210 - val_accuracy: 0.7612\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0432 - accuracy: 0.9801 - val_loss: 1.5017 - val_accuracy: 0.7690\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.0434 - accuracy: 0.9806 - val_loss: 1.4039 - val_accuracy: 0.7690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njt3wSqG6066",
        "outputId": "274d405f-6668-4192-bb2f-8f8d60e3e844"
      },
      "source": [
        "# Make predictionas with our bidirectional model\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.5147070e-04],\n",
              "       [6.0625076e-01],\n",
              "       [9.9987400e-01],\n",
              "       [7.7414781e-02],\n",
              "       [1.3862204e-05],\n",
              "       [9.9753201e-01],\n",
              "       [5.7186313e-02],\n",
              "       [9.9996722e-01],\n",
              "       [9.9992263e-01],\n",
              "       [6.4514476e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9tn0GQo7A5U",
        "outputId": "4db26e21-ba3b-4874-be7a-34c242489b9f"
      },
      "source": [
        "# Convert pred probs to pred labels \n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 0., 1., 1., 1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "av5I0l4p7MOI",
        "outputId": "bca94d53-0fbd-4cf1-babb-6e8c3e30052f"
      },
      "source": [
        "# Calculate the results of our bidirectional model\n",
        "model_4_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.9028871391076,\n",
              " 'f1': 0.7660901868079131,\n",
              " 'precision': 0.772410916855732,\n",
              " 'recall': 0.7690288713910761}"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq29sr6y7TFc",
        "outputId": "6e48b57f-460a-4b4c-cc21-3676119ba72e"
      },
      "source": [
        "model_3_results"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.50918635170603,\n",
              " 'f1': 0.7632813381351602,\n",
              " 'precision': 0.766006698423534,\n",
              " 'recall': 0.7650918635170604}"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1heX70jK7fPe"
      },
      "source": [
        "## Convolutional Neural Networks for Text (and other types of sequences)\n",
        "\n",
        "We have used CNNs for images but images are typically 2D (height x Width)... however, our text data is 1D.\n",
        "\n",
        "Previously we have used Conv2D for our image data but now we are going to use Conv1D.\n",
        "\n",
        "The typical structure of a Conv1D model for sequences , in our case , text:\n",
        "\n",
        "```\n",
        "Inputs (text) -> Tokenization -> Embedding -> Layer(s) (typically Conv1D + Pooling) -> Output (class probabilities)```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCftxuKq8uQL"
      },
      "source": [
        "### Model 5: Conv1D\n",
        "\n",
        "For different explainations of parameters see:\n",
        "* https://poloclub.github.io/cnn-explainer/\n",
        "* Difference between `same` and `valid` padding: https://stackoverflow.com/questions/37674306/what-is-the-difference-between-same-and-valid-padding-in-tf-nn-max-pool-of-t#:~:text=VALID%20%3A%20Don't%20apply%20any,filter%20and%20stride%20you%20specified."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV5Rf8vJ9VQH",
        "outputId": "2397a2aa-1702-47ad-e8bd-f8521726c6de"
      },
      "source": [
        "# Test out our embeddingl layer, Conv1D layer and max pooling\n",
        "embedding_test = embedding(text_vectorizer(['this is a test sentences'])) # turn target sequences into embedding\n",
        "conv_1d = layers.Conv1D(filters=32,\n",
        "                        kernel_size=5, # this is also referred to as an ngram of 5 (meaning it looks at 5 words at a time)\n",
        "                        activation='relu',\n",
        "                        padding='valid')\n",
        "conv_1d_output = conv_1d(embedding_test) # pass test embedding through conv1d layer\n",
        "max_pool = layers.GlobalMaxPool1D()\n",
        "max_pool_output = max_pool(conv_1d_output) # equivalent to \"get the most important feature with the highest value\"\n",
        "\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwNyo_Iz-bF8",
        "outputId": "cb8003e1-926c-4bd8-d17b-e0d20ddec816"
      },
      "source": [
        "embedding_test = embedding(text_vectorizer(['this is a test sentences'])) # turn target sequences into embedding\n",
        "conv_1d = layers.Conv1D(filters=32,\n",
        "                        kernel_size=5,\n",
        "                        activation='relu',\n",
        "                        padding='same')\n",
        "conv_1d_output = conv_1d(embedding_test) # pass test embedding through conv1d layer\n",
        "max_pool = layers.GlobalMaxPool1D()\n",
        "max_pool_output = max_pool(conv_1d_output) # equivalent to \"get the most important feature with the highest value\"\n",
        "\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 15, 32]), TensorShape([1, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhRiIocu-zJS"
      },
      "source": [
        "# embedding_test"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofh0w7sbE9vi"
      },
      "source": [
        "# conv_1d_output"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-SSJqbgFDGM"
      },
      "source": [
        "# max_pool_output"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}